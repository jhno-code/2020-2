{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Funciones Basicas Mpi_ hasta send y recv",
      "provenance": [],
      "collapsed_sections": [
        "kVWqN3EhJFbJ",
        "LJ_ThE3-KthZ",
        "Vww7AO93S8QD",
        "bXSiO5dGuJda",
        "49L8NojO6axL",
        "XxKI85d8LLll",
        "UKgBEDizMkRM",
        "lFx0VyZzN1Aw",
        "eJQfgyqlOTCr",
        "o6bvSqgMPeyt",
        "57wzDFu2xxvW",
        "n3eZ1sN1yVsK",
        "tNe1kQLpyqh2",
        "FcckAX8G0Pd-",
        "ocfu_ZYw3QCz",
        "0gcBP4q93eCj",
        "IGWlHIPh4t08",
        "cwiw83d44_gR",
        "PrwM90WO6jKv",
        "YRLLMm9j7iOA",
        "JnO-S8V37tpD",
        "P74yRNds9SBx",
        "gL2CQgIo-xTd",
        "1g5HzFU1--zY",
        "H9EYqJldBRS-",
        "tIw9YI6GB5go",
        "mPVwi5W4DpwJ",
        "-eCGJi2hEOC1",
        "qKhQXI7oFRMf",
        "t65YHXekHbBK"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhno-code/2020-2/blob/main/Funciones_Basicas_Mpi__hasta_send_y_recv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgFkKAPyS3b0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXMYxZtKyP0I"
      },
      "source": [
        "# Distributed Parallel Programming Patterns using mpi4py\n",
        "Libby Shoop, Macalester College\n",
        "\n",
        "¡Bienvenido!\n",
        "\n",
        "Este libro contiene algunos ejemplos que ilustran los conceptos fundamentales básicos de la computación distribuida utilizando código Python. El tipo de computación que ilustran estos ejemplos se llama * paso de mensajes *. El paso de mensajes es una forma de programación que se basa en procesos que se comunican entre sí para coordinar su trabajo. El paso de mensajes se puede utilizar en una sola computadora multinúcleo o con un grupo de computadoras.\n",
        "\n",
        "\n",
        "### Patrones de software\n",
        "\n",
        "Los patrones en el software son implementaciones comunes que los profesionales han utilizado una y otra vez para realizar tareas. A medida que los profesionales los usan repetidamente, la comunidad comienza a darles nombres y catalogarlos, convirtiéndolos a menudo en funciones de biblioteca reutilizables. Los ejemplos que verá en este libro se basan en patrones documentados que se han utilizado para resolver diferentes problemas mediante el paso de mensajes entre procesos. El paso de mensajes es una forma de computación distribuida que usa procesos, que se pueden usar en grupos de computadoras o máquinas multinúcleo.\n",
        "\n",
        "En muchos de estos ejemplos, el nombre del patrón es parte del nombre del archivo de código Python. También verá que, a menudo, las funciones de la biblioteca MPI también toman el nombre del patrón, y la implementación de esas funciones contiene el patrón que los profesionales utilizan con frecuencia. Estos ejemplos de código de patrón que le mostramos aquí, denominados patternlets, se basan en el trabajo original de Joel Adams:\n",
        "\n",
        "Adams, Joel C. \"Patternlets: una herramienta de enseñanza para presentar a los estudiantes los patrones de diseño paralelos\". Taller del Simposio Internacional de Procesamiento Distribuido y Paralelo del IEEE 2015. IEEE, 2015.\n",
        "\n",
        "Para ejecutar estos ejemplos, primero necesitará instalar la biblioteca mpi4py ejecutando este código (esto generalmente llevará un tiempo instalarlo la primera vez):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVgDVtdkxrgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a41daf7-7ad5-4a16-893d-ebfeecfa767b"
      },
      "source": [
        "! pip install mpi4py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.6/dist-packages (3.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqLzdrkgv2rw"
      },
      "source": [
        "![Important symbol](https://drive.google.com/uc?id=1AWRLAqeaqi7SG7PHyOVywZRuMDK9Z2_s)**Important:** \n",
        "Importante: tendrá que volver a ejecutar esta celda después de desconectarse durante bastante tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uryzb1Wy-hlp"
      },
      "source": [
        "# Patrones de estructura del programa\n",
        "\n",
        "> Bloque con sangría\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdWhWJMLzUIm"
      },
      "source": [
        "## Single Program, Multiple Data SPMD\n",
        "\n",
        "1.   Elemento de lista\n",
        "2.   Elemento de lista\n",
        "\n",
        "\n",
        "\n",
        "This code forms the basis of all of the other examples that follow. It is the fundamental way we structure parallel programs today.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djhcbZEkzIAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8ff2a3-7e8f-4700-ae59-4b6fb689edd3"
      },
      "source": [
        "%%writefile ejercicio1.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    \n",
        "    print(\"Saludos desde el proceso {} de {} \"\\\n",
        "    .format(id, numProcesses))\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting ejercicio1.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqOAtb4G4-e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730d222f-0e7c-485c-eedd-462c63ea3fb2"
      },
      "source": [
        "! mpirun --allow-run-as-root -np 5 python ejercicio1.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saludos desde el proceso 0 de 5 \n",
            "Saludos desde el proceso 1 de 5 \n",
            "Saludos desde el proceso 4 de 5 \n",
            "Saludos desde el proceso 3 de 5 \n",
            "Saludos desde el proceso 2 de 5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR2tfQ8v8RVa"
      },
      "source": [
        "The fundamental idea of message passing programs can be illustrated like this:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1wpQaFiaubIcQBV9Lw_jwOU0y2-K-EChW)\n",
        "\n",
        "Cada proceso se configura dentro de una red de comunicación para poder comunicarse con todos los demás procesos a través de enlaces de comunicación. Cada proceso está configurado para tener su propio número, o id, que comienza en 0.\n",
        "\n",
        "Nota: Cada proceso tiene sus propias copias de las 4 variables de datos anteriores. Entonces, aunque hay un solo programa, se ejecuta varias veces en procesos separados, cada uno con sus propios valores de datos. Esta es la razón del nombre del patrón que representa este código: programa único, datos múltiples. La línea de impresión al final de main () representa las múltiples salidas de datos diferentes producidas por cada proceso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSEhP3vv-_yX"
      },
      "source": [
        "## Master-Worker\n",
        "Este también es un patrón muy común que se usa en programación paralela y distribuida. Aquí está el pequeño código ilustrativo de muestra. Revísalo y responde esto: ¿Qué es diferente entre este ejemplo y el anterior?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlF-_TYc_uKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6141f0af-5a26-4030-d3af-a1429d02fd21"
      },
      "source": [
        "%%writefile 01masterWorker.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    if id == 0:\n",
        "        print(\"Saludos del maestro, {} de {} en {}\"\\\n",
        "        .format(id, numProcesses, myHostName))\n",
        "    else:\n",
        "        print(\"Saludos del trabajador, {} de {} en {}\"\\\n",
        "        .format(id, numProcesses, myHostName))\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 01masterWorker.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ0rjAxS_9xK"
      },
      "source": [
        "La respuesta a la pregunta anterior ilustra lo que podemos hacer con este patrón: basándonos en la identificación del proceso, podemos hacer que un proceso lleve a cabo algo diferente a los demás. Este concepto se utiliza mucho como un medio para coordinar actividades, donde un proceso, a menudo llamado maestro, tiene la responsabilidad de entregar el trabajo y realizar un seguimiento de los resultados. Veremos esto en ejemplos posteriores.\n",
        "\n",
        "**Note:**\n",
        "Por convención, el proceso de coordinación maestro suele ser el proceso número 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8HeRMx-APS2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "50527473-2870-4cc9-b324-74d23cc36fbf"
      },
      "source": [
        "! mpirun --allow-run-as-root -np 6 python 01masterWorker.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saludos del trabajador, 1 de 6 en 4ea9d432a738\n",
            "Saludos del trabajador, 4 de 6 en 4ea9d432a738\n",
            "Saludos del maestro, 0 de 6 en 4ea9d432a738\n",
            "Saludos del trabajador, 2 de 6 en 4ea9d432a738\n",
            "Saludos del trabajador, 3 de 6 en 4ea9d432a738\n",
            "Saludos del trabajador, 5 de 6 en 4ea9d432a738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9paZLu4Xt4Jm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Eyj6sa7GoXu"
      },
      "source": [
        "### Exercises:\n",
        "\n",
        "- Vuelva a ejecutar, utilizando un número variable de procesos del 1 al 8 (es decir, varíe el argumento después de -np).\n",
        "\n",
        "- Explique qué permanece igual y qué cambia a medida que cambia el número de procesos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1uIEnUS-JGG"
      },
      "source": [
        "# Descomposición usando paralelismo para patrones de bucles\n",
        "\n",
        "La forma más común de completar una tarea repetida en cualquier lenguaje de programa es un bucle. Usamos bucles porque queremos hacer un cierto número de tareas, muy a menudo porque queremos trabajar en un conjunto de elementos de datos que se encuentran en una lista o una matriz, o alguna otra estructura de datos. Si el trabajo a realizar en cada ciclo es independiente de las iteraciones anteriores, podemos usar procesos separados para hacer partes del ciclo de forma independiente. Este patrón de estructura de programa se denomina patrón de bucle para paralelizar, que es una estrategia de implementación para la descomposición del trabajo a realizar en partes más pequeñas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVWqN3EhJFbJ"
      },
      "source": [
        "## Parallel Loop Split into Equal Sized Chunks -> G1\n",
        "\n",
        "In the code below, notice the use of the variable called `REPS`. This is designed to be the total amount or work, or repetitions, that the for loop is accomplishing. This particular code is designed so that if those repetitions do not divide equally by the number of processes, then the program will stop with a warning message printed by the master process.\n",
        "\n",
        "Remember that because this is still also a SPMD program, all processes execute the code in the part of the if statement that evaluates to True. Each process has its own id, and we can determine how many processes there are, so we can choose where in the overall number of REPs of the loop each process will execute.\n",
        "\n",
        "En el código siguiente, observe el uso de la variable llamada \"REPS\". Esto está diseñado para ser la cantidad total de trabajo, o repeticiones, que el ciclo for está logrando. Este código en particular está diseñado para que si esas repeticiones no se dividen equitativamente por el número de procesos, el programa se detendrá con un mensaje de advertencia impreso por el proceso maestro.\n",
        "\n",
        "Recuerde que debido a que también es un programa SPMD, todos los procesos ejecutan el código en la parte de la instrucción if que se evalúa como Verdadero. Cada proceso tiene su propia identificación, y podemos determinar cuántos procesos hay, por lo que podemos elegir en qué parte del número total de REP del ciclo se ejecutará cada proceso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OpxV7pnJ_u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad35b92-a150-4846-f407-8b072a551914"
      },
      "source": [
        "%%writefile 02parallelLoopEqualChunks.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    REPS = 8\n",
        "\n",
        "    if ((REPS % numProcesses) == 0 and numProcesses <= REPS):\n",
        "        # How much of the loop should a process work on?\n",
        "        chunkSize = int(REPS / numProcesses) #1\n",
        "        start = id * chunkSize \n",
        "        stop = start + chunkSize\n",
        "\n",
        "        # do the work within the range set aside for this process\n",
        "        for i in range(start, stop): # 0 a 4\n",
        "            print(\"On {}: Process {} is performing iteration {}\"\\\n",
        "            .format(myHostName, id, i))\n",
        "    else:\n",
        "        # cannot break into equal chunks; one process reports the error\n",
        "        if id == 0 :\n",
        "            print(\"Please run with number of processes divisible by \\\n",
        "and less than or equal to {}.\".format(REPS))\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 02parallelLoopEqualChunks.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBshPRYXLLhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40685e1-e970-43e1-9a97-f29d17bf6507"
      },
      "source": [
        "! mpirun --allow-run-as-root -np 4 python 02parallelLoopEqualChunks.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On aa7fe3e77f51: Process 1 is performing iteration 2\n",
            "On aa7fe3e77f51: Process 2 is performing iteration 4\n",
            "On aa7fe3e77f51: Process 1 is performing iteration 3\n",
            "On aa7fe3e77f51: Process 0 is performing iteration 0\n",
            "On aa7fe3e77f51: Process 3 is performing iteration 6\n",
            "On aa7fe3e77f51: Process 2 is performing iteration 5\n",
            "On aa7fe3e77f51: Process 0 is performing iteration 1\n",
            "On aa7fe3e77f51: Process 3 is performing iteration 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ_ThE3-KthZ"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "- Run, using these numbers of processes, N: 1, 2, 4, and 8 (i.e., vary the  argument to -np).\n",
        "- Change REPS to 16 in the code and rerun it. Then rerun with mpirun, varying N again.\n",
        "- Explain how this pattern divides the iterations of the loop among the processes.\n",
        "\n",
        "Which of the following is the correct assignment of loop iterations to processes for this code, when REPS is 8 and numProcesses is 4?\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1eUsjxYdWXWqThO_rdLO91HaLqBLAAh_S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_okom_QiQeHe"
      },
      "source": [
        "## Parallel for Loop Program Structure: chunks of 1\n",
        "\n",
        "In the code below, we again use the variable called `REPS` for the total amount or work, or repetitions, that the for loop is accomplishing. This particular code is designed so that the number of repetitions should be more than or equal to the number of processes requested.\n",
        ".. note:: Typically in real problems, the number of repetitions is much higher than the number of processes. We keep it small here to illustrate what is happening.\n",
        "\n",
        "Like the last example all processes execute the code in the part of the if statement that evaluates to True. Note that in the for loop in this case we simply have process whose id is 0 start at iteration 0, then skip to 0 + numProcesses for its next iteration, and so on. Similarly, process 1 starts at iteration 1, skipping next to 1+ numProcesses, and continuing until REPs is reached. Each process performs similar single 'slices' or 'chunks of size 1' of the whole loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15B2xax5RXEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f307ab0a-bbe2-4eb4-d2c0-904b9f167d1e"
      },
      "source": [
        "%%writefile 03parallelLoopChunksOf1.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    REPS = 8\n",
        "\n",
        "    if (numProcesses <= REPS):\n",
        "\n",
        "        for i in range(id, REPS, numProcesses):\n",
        "            print(\"On {}: Process {} is performing iteration {}\"\\\n",
        "            .format(myHostName, id, i))\n",
        "\n",
        "    else:\n",
        "        # can't have more processes than work; one process reports the error\n",
        "        if id == 0 :\n",
        "            print(\"Please run with number of processes less than \\\n",
        "or equal to {}.\".format(REPS))\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 03parallelLoopChunksOf1.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ewx6nLSLgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f7c255-ff83-4e04-eecb-79d0919da9a4"
      },
      "source": [
        "! mpirun --allow-run-as-root -np 4 python 03parallelLoopChunksOf1.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On aa7fe3e77f51: Process 0 is performing iteration 0\n",
            "On aa7fe3e77f51: Process 0 is performing iteration 4\n",
            "On aa7fe3e77f51: Process 3 is performing iteration 3\n",
            "On aa7fe3e77f51: Process 3 is performing iteration 7\n",
            "On aa7fe3e77f51: Process 2 is performing iteration 2\n",
            "On aa7fe3e77f51: Process 2 is performing iteration 6\n",
            "On aa7fe3e77f51: Process 1 is performing iteration 1\n",
            "On aa7fe3e77f51: Process 1 is performing iteration 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vww7AO93S8QD"
      },
      "source": [
        "### Exercises\n",
        "- Run, using these numbers of processes, N: 1, 2, 4, and 8\n",
        "- Compare source code to output.\n",
        "- Change REPS to 16, save, rerun, varying N again.\n",
        "- Explain how this pattern divides the iterations of the loop among the processes.\n",
        "\n",
        "Which of the following is the correct assignment of loop iterations to processes for this code, when REPS is 8 and numProcesses is 4?\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1eUsjxYdWXWqThO_rdLO91HaLqBLAAh_S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGj_Em7xToeB"
      },
      "source": [
        "# Point to point communication: the message passing pattern\n",
        "\n",
        "The fundamental basis of coordination between independent processes is point-to-point communication between processes through the communication links in the MPI.COMM_WORLD. The form of communication is called message passing, where one process **sends** data to another one, who in turn must **receive** it from the sender. This is illustrated as follows:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1WJcOXq6Dn5TKF9Lng8r18_y2b23tHFe8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXSiO5dGuJda"
      },
      "source": [
        "## Message Passing Pattern: Key Problem\n",
        "\n",
        "The following code represents a common error that many programmers have inadvertently placed in their code. The concept behind this program is that we wish to use communication between pairs of processes, like this:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1UJ2acj6XzphD2W6gnutNF2YGp6wU529Z)\n",
        "\n",
        "For message passing to work between a pair of processes, one must send and the other must receive. If we wish to **exchange** data, then each process will need to perform both a send and a receive.\n",
        "The idea is that process 0 will send data to process 1, who will receive it from process 0. Process 1 will also send some data to process 0, who will receive it from process 1. Similarly, processes 2 and 3 will exchange messages: process 2 will send data to process 3, who will receive it from process 2. Process 3 will also send some data to process 2, who will receive it from process 3.\n",
        "\n",
        "If we have more processes, we still want to pair up processes together to exchange messages. The mechanism for doing this is to know your process id. If your id is odd (1, 3 in the above diagram), you will send and receive from your neighbor whose id is id - 1. If your id is even (0, 2), you will send and receive from your neighbor whose id is id + 1. This should work even if we add more than 4 processes, as long as the number of processes is divisible by 2.\n",
        "\n",
        "![warning sign](https://drive.google.com/uc?id=1SEqDBTBSKwNVXzn-zueWa7fBCm5b1_MB)\n",
        "**Warning** There is a problem with the following code called *deadlock*. This happens when every process is waiting on an action from another process. The program cannot complete. **To stop the program, choose the small square that appears after you choose to run the mpirun cell.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_-_ypqDvAM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504ea8aa-3d64-4818-9fce-1eb950d09115"
      },
      "source": [
        "%%writefile 04messagePssingDeadlock.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "# function to return whether a number of a process is odd or even\n",
        "def odd(number):\n",
        "    if (number % 2) == 0:\n",
        "        return False\n",
        "    else :\n",
        "        return True\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    if numProcesses > 1 and not odd(numProcesses):\n",
        "        sendValue = id # 0\n",
        "        if odd(id):\n",
        "            #odd processes receive from their paired 'neighbor', then send\n",
        "            receivedValue = comm.recv(source=id-1)\n",
        "            comm.send(sendValue, dest=id-1)\n",
        "        else :\n",
        "            #even processes receive from their paired 'neighbor', then send\n",
        "            receivedValue = comm.recv(source=id+1) # id=1\n",
        "            comm.send(sendValue, dest=id+1) # 0, dest=1\n",
        "\n",
        "        print(\"Process {} of {} on {} computed {} and received {}\"\\\n",
        "        .format(id, numProcesses, myHostName, sendValue, receivedValue)) # 0,2,rtwww, 0, 1\n",
        "\n",
        "    else :\n",
        "        if id == 0:\n",
        "            print(\"Please run this program with the number of processes \\\n",
        "positive and even\")\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 04messagePssingDeadlock.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbbAxy7vvYwW"
      },
      "source": [
        "! mpirun --allow-run-as-root -np 2 python 04messagePssingDeadlock.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MLayXixxraM"
      },
      "source": [
        "![warning sign](https://drive.google.com/uc?id=1SEqDBTBSKwNVXzn-zueWa7fBCm5b1_MB)Remember,**To stop the program, choose the small square that appears after you choose to run the mpirun cell.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49L8NojO6axL"
      },
      "source": [
        "#### What causes the deadlock?\n",
        "\n",
        "Each process, regardless of its id, will execute a receive request first. In this model, recv is a **blocking** function- it will not continue until it gets data from a send. So every process is blocked waiting to receive a message.\n",
        "\n",
        "#### Can you think of how to fix this problem?\n",
        "\n",
        "Since recv is a **blocking** function, we need to have some processes send first, while others correspondingly recv first from those who send first. This provides coordinated exchanges.\n",
        "\n",
        "Go to the next example to see the solution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxKI85d8LLll"
      },
      "source": [
        "## Message Passing Patterns: avoiding deadlock\n",
        "\n",
        "Let's look at a few more correct message passing examples.\n",
        "\n",
        "### Fix the Deadlock\n",
        "\n",
        "To fix deadlock of the previous example, we coordinate the communication between pairs of processes so that there is an ordering of sends and receives between them.\n",
        "\n",
        "![Important symbol](https://drive.google.com/uc?id=1AWRLAqeaqi7SG7PHyOVywZRuMDK9Z2_s)**Important:** The new code corrects deadlock with a simple change: odd process sends first, even process receives first. *This is the proper pattern for exchanging data between pairs of processes.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO8N49wuL0fR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948d50e4-28e3-4815-ab8c-836b1f8a8f37"
      },
      "source": [
        "%%writefile 05messagePassing.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "# function to return whether a number of a process is odd or even\n",
        "def odd(number):\n",
        "    if (number % 2) == 0:\n",
        "        return False\n",
        "    else :\n",
        "        return True\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    if numProcesses > 1 and not odd(numProcesses):\n",
        "        sendValue = id\n",
        "        if odd(id):\n",
        "            #odd processes send to their paired 'neighbor', then receive from\n",
        "            comm.send(sendValue, dest=id-1)\n",
        "            receivedValue = comm.recv(source=id-1)\n",
        "        else :\n",
        "            #even processes receive from their paired 'neighbor', then send\n",
        "            receivedValue = comm.recv(source=id+1)\n",
        "            comm.send(sendValue, dest=id+1)\n",
        "\n",
        "        print(\"Process {} of {} on {} computed {} and received {}\"\\\n",
        "        .format(id, numProcesses, myHostName, sendValue, receivedValue))\n",
        "\n",
        "    else :\n",
        "        if id == 0:\n",
        "            print(\"Please run this program with the number of processes \\\n",
        "positive and even\")\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 05messagePassing.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zl-Ms_kMMql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18babda4-72e4-4964-d13a-87263e4c0e6a"
      },
      "source": [
        "! mpirun --allow-run-as-root -np 2 python 05messagePassing.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process 0 of 2 on aa7fe3e77f51 computed 0 and received 1\n",
            "Process 1 of 2 on aa7fe3e77f51 computed 1 and received 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feezQHWCbGeC"
      },
      "source": [
        "# Nueva sección"
      ]
    }
  ]
}